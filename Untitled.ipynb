{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93fbbd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import dlib\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63f44832",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d4292fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread('test1.jpg')\n",
    "\n",
    "bboxes = classifier.detectMultiScale(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d84ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for box in bboxes:\n",
    "    x, y, width, height = box\n",
    "    x2, y2 = x + width, y + height\n",
    "    im[y:y2, x:x2] = cv2.medianBlur(im[y:y2, x:x2], 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bdf683",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('face detection', im)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "111f99c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_mask(img, line_size, blur_value):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_blur = cv2.medianBlur(gray, blur_value)\n",
    "    edges = cv2.adaptiveThreshold(gray_blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, line_size, blur_value)\n",
    "    return edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72352c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_quantization(img, k):\n",
    "    data = np.float32(img).reshape((-1, 3))\n",
    "\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 20, 0.001)\n",
    "\n",
    "    ret, label, center = cv2.kmeans(data, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    center = np.uint8(center)\n",
    "    result = center[label.flatten()]\n",
    "    result = result.reshape(img.shape)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b1da346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartoon(img):\n",
    "\n",
    "    data = np.float32(img).reshape((-1, 3))\n",
    "    line_size = 7\n",
    "    blur_value = 7\n",
    "\n",
    "    edges = edge_mask(img, line_size, blur_value)\n",
    "    total_color = 20\n",
    "    img = color_quantization(img, total_color)\n",
    "    blurred = cv2.bilateralFilter(img, d=7, sigmaColor=200,sigmaSpace=200)\n",
    "    cartoon = cv2.bitwise_and(blurred, blurred, mask=edges)\n",
    "    return cartoon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0296fbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the video from the camera\n",
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "# Load the Haar cascade classifier for detecting faces\n",
    "# face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Loop through each frame of the video\n",
    "while True:\n",
    "    # Read the current frame\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    frame_new = cartoon(frame)\n",
    "       \n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow('Video', frame_new)\n",
    "\n",
    "    # Check if the user pressed the 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48d9430d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract frames\n",
    "def FrameCapture(path):\n",
    "      \n",
    "    # Path to video file\n",
    "    vidObj = cv2.VideoCapture(path)\n",
    "  \n",
    "    # Used as counter variable\n",
    "    count = 0\n",
    "  \n",
    "    # checks whether frames were extracted\n",
    "    success = 1\n",
    "  \n",
    "    while success:\n",
    "  \n",
    "        # vidObj object calls read\n",
    "        # function extract frames\n",
    "        success, image = vidObj.read()\n",
    "        if image is None:\n",
    "            break\n",
    "        # Saves the frames with frame-count\n",
    "        cv2.imwrite(\"images/frame%d.jpg\" % count, image)\n",
    "  \n",
    "        count += 1\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d24d793f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster(input_folder, output_folder):\n",
    "    detector = dlib.get_frontal_face_detector() \n",
    "    sp = dlib.shape_predictor('shape_predictor_5_face_landmarks.dat' ) \n",
    "    facerec = dlib.face_recognition_model_v1('dlib_face_recognition_resnet_model_v1.dat' ) \n",
    "\n",
    "    descriptors = []\n",
    "    images = []\n",
    "\n",
    "    # Load the images from input folder\n",
    "    for f in os.listdir(input_folder):\n",
    "        if \".jpg\" in f:\n",
    "            print(\"Processing file: {}\".format(f))\n",
    "            img = dlib.load_rgb_image(input_folder + f)\n",
    "            dets = detector(img, 1)\n",
    "            print(\"Number of faces detected: {}\".format(len(dets)))\n",
    "\n",
    "            for k, d in enumerate(dets):\n",
    "                shape = sp(img, d)\n",
    "                face_descriptor = facerec.compute_face_descriptor(img, shape)\n",
    "                descriptors.append(face_descriptor)\n",
    "                images.append((img, shape))\n",
    "\n",
    "\n",
    "    labels = dlib.chinese_whispers_clustering(descriptors, 0.5)\n",
    "    num_classes = len(set(labels)) # Total number of clusters\n",
    "    print(\"Number of clusters: {}\".format(num_classes))\n",
    "\n",
    "    for i in range(0, num_classes):\n",
    "        indices = []\n",
    "        class_length = len([label for label in labels if label == i])\n",
    "        for j, label in enumerate(labels):\n",
    "            if label == i:\n",
    "                indices.append(j)\n",
    "        print(\"Indices of images in the cluster {0} : {1}\".format(str(i),str(indices)))\n",
    "        print(\"Size of cluster {0} : {1}\".format(str(i),str(class_length)))\n",
    "        output_folder_path = output_folder + '/output' + str(i) # Output folder for each cluster\n",
    "        os.path.normpath(output_folder_path)\n",
    "        os.makedirs(output_folder_path)\n",
    "\n",
    "        # Save each face to the respective cluster folder\n",
    "        for k, index in enumerate(indices):\n",
    "            img, shape = images[index]\n",
    "            file_path = os.path.join(output_folder_path,\"face_\"+str(k)+\"_\"+str(i))\n",
    "            dlib.save_face_chip(img, shape, file_path, size = 150, padding = 0.25)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b9a50b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "import time\n",
    "\n",
    "def extract_index_nparray(nparray):\n",
    "    index = None\n",
    "    for num in nparray[0]:\n",
    "        index = num\n",
    "        break\n",
    "    return index\n",
    "\n",
    "def face_swap(img, img2):\n",
    "    \n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "    mask = np.zeros_like(img_gray)\n",
    "\n",
    "    img2_new_face = np.zeros_like(img2)\n",
    "\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "    # Face 1\n",
    "    faces = detector(img_gray)\n",
    "    for face in faces:\n",
    "        landmarks = predictor(img_gray, face)\n",
    "        landmarks_points = []\n",
    "        for n in range(0, 68):\n",
    "            x = landmarks.part(n).x\n",
    "            y = landmarks.part(n).y\n",
    "            landmarks_points.append((x, y))\n",
    "\n",
    "            # cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "\n",
    "        points = np.array(landmarks_points, np.int32)\n",
    "        convexhull = cv2.convexHull(points)\n",
    "        # cv2.polylines(img, [convexhull], True, (255, 0, 0), 3)\n",
    "        cv2.fillConvexPoly(mask, convexhull, 255)\n",
    "\n",
    "        face_image_1 = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "        # Delaunay triangulation\n",
    "        rect = cv2.boundingRect(convexhull)\n",
    "        subdiv = cv2.Subdiv2D(rect)\n",
    "        subdiv.insert(landmarks_points)\n",
    "        triangles = subdiv.getTriangleList()\n",
    "        triangles = np.array(triangles, dtype=np.int32)\n",
    "\n",
    "        indexes_triangles = []\n",
    "        for t in triangles:\n",
    "            pt1 = (t[0], t[1])\n",
    "            pt2 = (t[2], t[3])\n",
    "            pt3 = (t[4], t[5])\n",
    "\n",
    "            index_pt1 = np.where((points == pt1).all(axis=1))\n",
    "            index_pt1 = extract_index_nparray(index_pt1)\n",
    "\n",
    "            index_pt2 = np.where((points == pt2).all(axis=1))\n",
    "            index_pt2 = extract_index_nparray(index_pt2)\n",
    "\n",
    "            index_pt3 = np.where((points == pt3).all(axis=1))\n",
    "            index_pt3 = extract_index_nparray(index_pt3)\n",
    "\n",
    "            if index_pt1 is not None and index_pt2 is not None and index_pt3 is not None:\n",
    "                triangle = [index_pt1, index_pt2, index_pt3]\n",
    "                indexes_triangles.append(triangle)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Face 2\n",
    "    faces2 = detector(img2_gray)\n",
    "    for face in faces2:\n",
    "        landmarks = predictor(img2_gray, face)\n",
    "        landmarks_points2 = []\n",
    "        for n in range(0, 68):\n",
    "            x = landmarks.part(n).x\n",
    "            y = landmarks.part(n).y\n",
    "            landmarks_points2.append((x, y))\n",
    "\n",
    "            #cv2.circle(img2, (x, y), 3, (0, 255, 0), -1)\n",
    "        points2 = np.array(landmarks_points2, np.int32)\n",
    "        convexhull2 = cv2.convexHull(points2)\n",
    "\n",
    "    # Triangulation of both faces\n",
    "    for triangle_index in indexes_triangles:\n",
    "        # Triangulation of the first face\n",
    "        tr1_pt1 = landmarks_points[triangle_index[0]]\n",
    "        tr1_pt2 = landmarks_points[triangle_index[1]]\n",
    "        tr1_pt3 = landmarks_points[triangle_index[2]]\n",
    "        triangle1 = np.array([tr1_pt1, tr1_pt2, tr1_pt3], np.int32)\n",
    "\n",
    "        rect1 = cv2.boundingRect(triangle1)\n",
    "        (x, y, w, h) = rect1\n",
    "        cropped_triangle = img[y: y + h, x: x + w]\n",
    "        #print(y + h, x + w)\n",
    "        if y + h > img.shape[0] and x + w > img.shape[1]:\n",
    "            cropped_tr1_mask =  np.zeros((cropped_triangle.shape[0]  , w), np.uint8)\n",
    "            y = y - ((y + h) - img.shape[0])\n",
    "            cropped_tr1_mask =  np.zeros((h  , cropped_triangle.shape[1]), np.uint8)\n",
    "            x = x - ((x + w) - img.shape[1])\n",
    "        elif y + h > img.shape[0]:\n",
    "            cropped_tr1_mask =  np.zeros((cropped_triangle.shape[0]  , w), np.uint8)\n",
    "            y = y - ((y + h) - img.shape[0])\n",
    "        elif x + w > img.shape[1]:\n",
    "            cropped_tr1_mask =  np.zeros((h  , cropped_triangle.shape[1]), np.uint8)\n",
    "            x = x - ((x + w) - img.shape[1])  \n",
    "        else:\n",
    "            cropped_tr1_mask = np.zeros((h, w), np.uint8)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        points = np.array([[tr1_pt1[0] - x, tr1_pt1[1] - y],\n",
    "                          [tr1_pt2[0] - x, tr1_pt2[1] - y],\n",
    "                          [tr1_pt3[0] - x, tr1_pt3[1] - y]], np.int32)\n",
    "\n",
    "        cv2.fillConvexPoly(cropped_tr1_mask, points, 255)\n",
    "        #print(cropped_triangle.shape,cropped_tr1_mask.shape, y + h, x + w)\n",
    "        cropped_triangle = cv2.bitwise_and(cropped_triangle, cropped_triangle,\n",
    "                                           mask=cropped_tr1_mask)\n",
    "        \n",
    "\n",
    "        # cv2.line(img, tr1_pt1, tr1_pt2, (0, 0, 255), 2)\n",
    "        # cv2.line(img, tr1_pt3, tr1_pt2, (0, 0, 255), 2)\n",
    "        # cv2.line(img, tr1_pt1, tr1_pt3, (0, 0, 255), 2)\n",
    "\n",
    "        # Triangulation of second face\n",
    "        tr2_pt1 = landmarks_points2[triangle_index[0]]\n",
    "        tr2_pt2 = landmarks_points2[triangle_index[1]]\n",
    "        tr2_pt3 = landmarks_points2[triangle_index[2]]\n",
    "        triangle2 = np.array([tr2_pt1, tr2_pt2, tr2_pt3], np.int32)\n",
    "\n",
    "        rect2 = cv2.boundingRect(triangle2)\n",
    "        (x, y, w, h) = rect2\n",
    "        \n",
    "        cropped_triangle2 = img2[y: y + h, x: x + w]\n",
    "        if y + h > img2.shape[0]:\n",
    "            cropped_tr2_mask =  np.zeros((cropped_triangle2.shape[0]  , w), np.uint8)\n",
    "            y = y - ((y + h) - img2.shape[0])\n",
    "        else:\n",
    "            cropped_tr2_mask = np.zeros((h, w), np.uint8)\n",
    "        if x + w > img2.shape[1]:\n",
    "            cropped_tr1_mask =  np.zeros((h  , cropped_triangle.shape[1]), np.uint8)\n",
    "            x = x - ((x + w) - img.shape[1])\n",
    "                \n",
    "        else:\n",
    "            cropped_tr1_mask = np.zeros((h, w), np.uint8)\n",
    "        #print(cropped_tr2_mask.shape , cropped_triangle2.shape, y + h)\n",
    "        points2 = np.array([[tr2_pt1[0] - x, tr2_pt1[1] - y],\n",
    "                           [tr2_pt2[0] - x, tr2_pt2[1] - y],\n",
    "                           [tr2_pt3[0] - x, tr2_pt3[1] - y]], np.int32)\n",
    "\n",
    "        cv2.fillConvexPoly(cropped_tr2_mask, points2, 255)\n",
    "        #print(cropped_triangle2.shape, cropped_tr2_mask.shape)\n",
    "        cropped_triangle2 = cv2.bitwise_and(cropped_triangle2, cropped_triangle2,\n",
    "                                           mask=cropped_tr2_mask)\n",
    "\n",
    "        # cv2.line(img2, tr2_pt1, tr2_pt2, (0, 0, 255), 2)\n",
    "        # cv2.line(img2, tr2_pt3, tr2_pt2, (0, 0, 255), 2)\n",
    "        # cv2.line(img2, tr2_pt1, tr2_pt3, (0, 0, 255), 2)\n",
    "\n",
    "        # Warp triangles\n",
    "        points = np.float32(points)\n",
    "        points2 = np.float32(points2)\n",
    "        M = cv2.getAffineTransform(points, points2)\n",
    "        warped_triangle = cv2.warpAffine(cropped_triangle, M, (w, h))\n",
    "        \n",
    "        # Reconstructing destination face\n",
    "        img2_new_face_rect_area = img2_new_face[y: y + h, x: x + w]\n",
    "        #print(img2_new_face_rect_area.shape, warped_triangle.shape)\n",
    "        img2_new_face_rect_area = cv2.add(img2_new_face_rect_area, warped_triangle)\n",
    "        img2_new_face[y: y + h, x: x + w] = img2_new_face_rect_area\n",
    "\n",
    "    # Face swapped (putting 1st face into 2nd face)\n",
    "    img2_face_mask = np.zeros_like(img2_gray)\n",
    "    img2_head_mask = cv2.fillConvexPoly(img2_face_mask, convexhull2, 255)\n",
    "    img2_face_mask = cv2.bitwise_not(img2_head_mask)\n",
    "\n",
    "    img2_head_noface = np.zeros_like(img)\n",
    "\n",
    "    img2_head_noface = cv2.bitwise_and(img2, img2, mask=img2_face_mask)\n",
    "    result = cv2.add(img2_head_noface, img2_new_face)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b046035",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FrameCapture' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8_/_s9qgprn6wn2zs4vml_04m2c0000gn/T/ipykernel_27389/3820761868.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'images/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moutput_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'output/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mFrameCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.mov'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FrameCapture' is not defined"
     ]
    }
   ],
   "source": [
    "input_folder = 'images/'\n",
    "output_folder = 'output/'\n",
    "FrameCapture('test.mov')\n",
    "cluster(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b184c543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2da86f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_faces(input1, input2, input_folder):\n",
    "    im1 = face_recognition.load_image_file(input1)\n",
    "    im2 = face_recognition.load_image_file(input2)\n",
    "    input1_encoding = face_recognition.face_encodings(im1)[0]\n",
    "    input2_encoding = face_recognition.face_encodings(im2)[0]\n",
    "    count = 0\n",
    "    for f in os.listdir(input_folder):\n",
    "        index = 0\n",
    "        \n",
    "        im1_location = 0\n",
    "        im2_location = 0\n",
    "        face_locations = []\n",
    "        face_encodings = []\n",
    "        face_distances = []\n",
    "        im = cv2.imread(input_folder + f)\n",
    "        if im is not None:\n",
    "            im = im[:, :, ::-1]\n",
    "            face_locations = face_recognition.face_locations(im)\n",
    "            face_encodings = face_recognition.face_encodings(im, face_locations)\n",
    "\n",
    "            for i in face_encodings:\n",
    "\n",
    "                matches = face_recognition.compare_faces(input1_encoding, [i])\n",
    "                matches2 = face_recognition.compare_faces(input2_encoding, [i])\n",
    "                if True in matches:\n",
    "                    im1_location = face_locations[index]\n",
    "                if True in matches2:\n",
    "                    im2_location = face_locations[index]\n",
    "\n",
    "                if im1_location != 0 and im2_location != 0:\n",
    "                    im = im[:, :, ::-1]\n",
    "                    face1 = im[im1_location[0]: im1_location[2],im1_location[3]: im1_location[1]]\n",
    "                    face2 = im[im2_location[0]: im2_location[2],im2_location[3]: im2_location[1]]\n",
    "                    print(f)\n",
    "                     \n",
    "                    result1 = face_swap(face1,face2)\n",
    "                    result2 = face_swap(face1,face2)\n",
    "                    im[im1_location[0]: im1_location[2],im1_location[3]: im1_location[1]] = result1\n",
    "                    im[im2_location[0]: im2_location[2],im2_location[3]: im2_location[1]] = result2\n",
    "                    cv2.imwrite(\"final/frame%d.jpg\" % count, im)\n",
    "                    count += 1\n",
    "                    break\n",
    "                index += 1\n",
    "\n",
    "                \n",
    "\n",
    "                    \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a11cee53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame85.jpg\n",
      "frame91.jpg\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) /Users/runner/work/opencv-python/opencv-python/opencv/modules/core/src/arithm.cpp:230: error: (-215:Assertion failed) (mtype == CV_8U || mtype == CV_8S) && _mask.sameSize(*psrc1) in function 'binary_op'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8_/_s9qgprn6wn2zs4vml_04m2c0000gn/T/ipykernel_27389/2652297478.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfind_faces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output/output1/face_0_1.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"output/output0/face_0_0.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"images/\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/8_/_s9qgprn6wn2zs4vml_04m2c0000gn/T/ipykernel_27389/2292708006.py\u001b[0m in \u001b[0;36mfind_faces\u001b[0;34m(input1, input2, input_folder)\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                     \u001b[0mresult1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_swap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mface2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                     \u001b[0mresult2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_swap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mface2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0mim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mim1_location\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mim1_location\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mim1_location\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mim1_location\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/8_/_s9qgprn6wn2zs4vml_04m2c0000gn/T/ipykernel_27389/3536624091.py\u001b[0m in \u001b[0;36mface_swap\u001b[0;34m(img, img2)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillConvexPoly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcropped_tr1_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;31m#print(cropped_triangle.shape,cropped_tr1_mask.shape, y + h, x + w)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         cropped_triangle = cv2.bitwise_and(cropped_triangle, cropped_triangle,\n\u001b[0m\u001b[1;32m    121\u001b[0m                                            mask=cropped_tr1_mask)\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /Users/runner/work/opencv-python/opencv-python/opencv/modules/core/src/arithm.cpp:230: error: (-215:Assertion failed) (mtype == CV_8U || mtype == CV_8S) && _mask.sameSize(*psrc1) in function 'binary_op'\n"
     ]
    }
   ],
   "source": [
    "find_faces(\"output/output1/face_0_1.jpg\",\"output/output0/face_0_0.jpg\",\"images/\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06275572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd8fb9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070ae2e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
